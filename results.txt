SPARK_MAJOR_VERSION is set to 2, using Spark2
21/04/22 01:47:52 INFO SparkContext: Running Spark version 2.3.1.3.0.1.0-187
21/04/22 01:47:52 INFO SparkContext: Submitted application: spark-mini-project
21/04/22 01:47:52 INFO SecurityManager: Changing view acls to: root
21/04/22 01:47:52 INFO SecurityManager: Changing modify acls to: root
21/04/22 01:47:52 INFO SecurityManager: Changing view acls groups to: 
21/04/22 01:47:52 INFO SecurityManager: Changing modify acls groups to: 
21/04/22 01:47:52 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
21/04/22 01:47:52 INFO Utils: Successfully started service 'sparkDriver' on port 40441.
21/04/22 01:47:52 INFO SparkEnv: Registering MapOutputTracker
21/04/22 01:47:53 INFO SparkEnv: Registering BlockManagerMaster
21/04/22 01:47:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
21/04/22 01:47:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
21/04/22 01:47:53 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-25c445e6-bde6-4fa2-b4d6-29602f18c884
21/04/22 01:47:53 INFO MemoryStore: MemoryStore started with capacity 93.3 MB
21/04/22 01:47:53 INFO SparkEnv: Registering OutputCommitCoordinator
21/04/22 01:47:53 INFO log: Logging initialized @2515ms
21/04/22 01:47:53 INFO Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
21/04/22 01:47:53 INFO Server: Started @2601ms
21/04/22 01:47:53 INFO AbstractConnector: Started ServerConnector@2d4ad45d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
21/04/22 01:47:53 INFO Utils: Successfully started service 'SparkUI' on port 4040.
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@474be0b1{/jobs,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3103303e{/jobs/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@11de0b09{/jobs/job,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7695ce52{/jobs/job/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5ebf927e{/stages,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@3fd85ce3{/stages/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1318ecce{/stages/stage,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@146b664b{/stages/stage/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@40418694{/stages/pool,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@312a5b72{/stages/pool/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@10a4bac6{/storage,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5fb2cfa7{/storage/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@138b87e3{/storage/rdd,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7099af2b{/storage/rdd/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@455e5974{/environment,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@cd8798f{/environment/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@43a34368{/executors,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@7efe5cc0{/executors/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@495c2f92{/executors/threadDump,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6072337{/executors/threadDump/json,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@5fe6889c{/static,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@6006ec73{/,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@2ddc6c41{/api,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@1596efe9{/jobs/job/kill,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@a0f1914{/stages/stage/kill,null,AVAILABLE,@Spark}
21/04/22 01:47:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://sandbox-hdp.hortonworks.com:4040
21/04/22 01:47:53 INFO Executor: Starting executor ID driver on host localhost
21/04/22 01:47:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41473.
21/04/22 01:47:53 INFO NettyBlockTransferService: Server created on sandbox-hdp.hortonworks.com:41473
21/04/22 01:47:53 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
21/04/22 01:47:53 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 41473, None)
21/04/22 01:47:53 INFO BlockManagerMasterEndpoint: Registering block manager sandbox-hdp.hortonworks.com:41473 with 93.3 MB RAM, BlockManagerId(driver, sandbox-hdp.hortonworks.com, 41473, None)
21/04/22 01:47:53 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, sandbox-hdp.hortonworks.com, 41473, None)
21/04/22 01:47:53 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, sandbox-hdp.hortonworks.com, 41473, None)
21/04/22 01:47:53 INFO ContextHandler: Started o.s.j.s.ServletContextHandler@4eb69d{/metrics/json,null,AVAILABLE,@Spark}
21/04/22 01:47:54 INFO EventLoggingListener: Logging events to hdfs:/spark2-history/local-1619056073395
21/04/22 01:47:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 363.4 KB, free 92.9 MB)
21/04/22 01:47:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 30.4 KB, free 92.9 MB)
21/04/22 01:47:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sandbox-hdp.hortonworks.com:41473 (size: 30.4 KB, free: 93.3 MB)
21/04/22 01:47:55 INFO SparkContext: Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
21/04/22 01:47:55 INFO FileInputFormat: Total input files to process : 1
21/04/22 01:47:55 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
21/04/22 01:47:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/04/22 01:47:55 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/04/22 01:47:55 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:78
21/04/22 01:47:55 INFO DAGScheduler: Registering RDD 3 (groupByKey at /root/spark-mini-project/main.py:33)
21/04/22 01:47:55 INFO DAGScheduler: Registering RDD 7 (reduceByKey at /root/spark-mini-project/main.py:35)
21/04/22 01:47:55 INFO DAGScheduler: Got job 0 (runJob at SparkHadoopWriter.scala:78) with 1 output partitions
21/04/22 01:47:55 INFO DAGScheduler: Final stage: ResultStage 2 (runJob at SparkHadoopWriter.scala:78)
21/04/22 01:47:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
21/04/22 01:47:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
21/04/22 01:47:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/spark-mini-project/main.py:33), which has no missing parents
21/04/22 01:47:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 92.9 MB)
21/04/22 01:47:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.4 KB, free 92.9 MB)
21/04/22 01:47:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sandbox-hdp.hortonworks.com:41473 (size: 6.4 KB, free: 93.3 MB)
21/04/22 01:47:55 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1039
21/04/22 01:47:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /root/spark-mini-project/main.py:33) (first 15 tasks are for partitions Vector(0))
21/04/22 01:47:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
21/04/22 01:47:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, ANY, 7901 bytes)
21/04/22 01:47:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
21/04/22 01:47:56 INFO HadoopRDD: Input split: hdfs://sandbox-hdp.hortonworks.com:8020/user/admin/input/data.csv:0+993
21/04/22 01:47:56 INFO PythonRunner: Times: total = 523, boot = 364, init = 153, finish = 6
21/04/22 01:47:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1733 bytes result sent to driver
21/04/22 01:47:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1121 ms on localhost (executor driver) (1/1)
21/04/22 01:47:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
21/04/22 01:47:56 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 41835
21/04/22 01:47:56 INFO DAGScheduler: ShuffleMapStage 0 (groupByKey at /root/spark-mini-project/main.py:33) finished in 1.272 s
21/04/22 01:47:56 INFO DAGScheduler: looking for newly runnable stages
21/04/22 01:47:56 INFO DAGScheduler: running: Set()
21/04/22 01:47:56 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
21/04/22 01:47:56 INFO DAGScheduler: failed: Set()
21/04/22 01:47:56 INFO DAGScheduler: Submitting ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/spark-mini-project/main.py:35), which has no missing parents
21/04/22 01:47:56 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.9 KB, free 92.9 MB)
21/04/22 01:47:56 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.8 KB, free 92.9 MB)
21/04/22 01:47:56 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sandbox-hdp.hortonworks.com:41473 (size: 6.8 KB, free: 93.3 MB)
21/04/22 01:47:56 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
21/04/22 01:47:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at reduceByKey at /root/spark-mini-project/main.py:35) (first 15 tasks are for partitions Vector(0))
21/04/22 01:47:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
21/04/22 01:47:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, ANY, 7638 bytes)
21/04/22 01:47:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
21/04/22 01:47:56 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/04/22 01:47:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
21/04/22 01:47:57 INFO PythonRunner: Times: total = 47, boot = -382, init = 429, finish = 0
21/04/22 01:47:57 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1905 bytes result sent to driver
21/04/22 01:47:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 122 ms on localhost (executor driver) (1/1)
21/04/22 01:47:57 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
21/04/22 01:47:57 INFO DAGScheduler: ShuffleMapStage 1 (reduceByKey at /root/spark-mini-project/main.py:35) finished in 0.148 s
21/04/22 01:47:57 INFO DAGScheduler: looking for newly runnable stages
21/04/22 01:47:57 INFO DAGScheduler: running: Set()
21/04/22 01:47:57 INFO DAGScheduler: waiting: Set(ResultStage 2)
21/04/22 01:47:57 INFO DAGScheduler: failed: Set()
21/04/22 01:47:57 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
21/04/22 01:47:57 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 100.8 KB, free 92.8 MB)
21/04/22 01:47:57 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 36.2 KB, free 92.7 MB)
21/04/22 01:47:57 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sandbox-hdp.hortonworks.com:41473 (size: 36.2 KB, free: 93.2 MB)
21/04/22 01:47:57 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1039
21/04/22 01:47:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[12] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
21/04/22 01:47:57 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
21/04/22 01:47:57 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 7649 bytes)
21/04/22 01:47:57 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
21/04/22 01:47:57 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
21/04/22 01:47:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
21/04/22 01:47:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 2
21/04/22 01:47:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
21/04/22 01:47:57 INFO PythonRunner: Times: total = 43, boot = -121, init = 163, finish = 1
21/04/22 01:47:57 INFO FileOutputCommitter: Saved output of task 'attempt_20210422014755_0012_m_000000_0' to hdfs://sandbox-hdp.hortonworks.com:8020/user/admin/output
21/04/22 01:47:57 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sandbox-hdp.hortonworks.com:41473 in memory (size: 6.4 KB, free: 93.2 MB)
21/04/22 01:47:57 INFO SparkHadoopMapRedUtil: attempt_20210422014755_0012_m_000000_0: Committed
21/04/22 01:47:57 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 2110 bytes result sent to driver
21/04/22 01:47:57 INFO BlockManagerInfo: Removed broadcast_2_piece0 on sandbox-hdp.hortonworks.com:41473 in memory (size: 6.8 KB, free: 93.2 MB)
21/04/22 01:47:57 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 196 ms on localhost (executor driver) (1/1)
21/04/22 01:47:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
21/04/22 01:47:57 INFO DAGScheduler: ResultStage 2 (runJob at SparkHadoopWriter.scala:78) finished in 0.233 s
21/04/22 01:47:57 INFO DAGScheduler: Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 1.751230 s
21/04/22 01:47:57 INFO SparkHadoopWriter: Job job_20210422014755_0012 committed.
21/04/22 01:47:57 INFO SparkContext: Invoking stop() from shutdown hook
21/04/22 01:47:57 INFO AbstractConnector: Stopped Spark@2d4ad45d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
21/04/22 01:47:57 INFO SparkUI: Stopped Spark web UI at http://sandbox-hdp.hortonworks.com:4040
21/04/22 01:47:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
21/04/22 01:47:57 INFO MemoryStore: MemoryStore cleared
21/04/22 01:47:57 INFO BlockManager: BlockManager stopped
21/04/22 01:47:57 INFO BlockManagerMaster: BlockManagerMaster stopped
21/04/22 01:47:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
21/04/22 01:47:57 INFO SparkContext: Successfully stopped SparkContext
21/04/22 01:47:57 INFO ShutdownHookManager: Shutdown hook called
21/04/22 01:47:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-3842d312-2f4e-4c2a-86d4-a433c19cd3dc/pyspark-fedce7e1-8667-4646-8ea8-5904334c4b8a
21/04/22 01:47:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-3842d312-2f4e-4c2a-86d4-a433c19cd3dc
21/04/22 01:47:57 INFO ShutdownHookManager: Deleting directory /tmp/spark-c5b322ab-135e-47bf-96aa-d6145e9ffeef
